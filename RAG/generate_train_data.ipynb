{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d16ba97",
   "metadata": {},
   "source": [
    "# Generate error message retrieve data\n",
    "## Load LTL tasks from txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8974754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U(O(N(f), E(U(a, b))), N(f))\n",
      "\n",
      "956\n"
     ]
    }
   ],
   "source": [
    "## These tasks are used to train the embedding model and should be stored in '../GA/tasks.txt'.\n",
    "file_path = \"../GA/tasks.txt\"\n",
    "with open(file_path) as f:\n",
    "    tasks = f.readlines()\n",
    "print(tasks[0])\n",
    "print(len(tasks))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28bae149",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the prefix format of these tasks into the original format\n",
    "def parse(task):\n",
    "    return task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa9194",
   "metadata": {},
   "source": [
    "## Import OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fa84548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, openai\n",
    "# You need to set your OPENAI API key here\n",
    "# https://beta.openai.com/account/api-keys\n",
    "#openai.api_key = \"TO_BE_SET\"\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6edac9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"Given a linear temporal logic task {ltlt}, assume this task doesn't satisfy the expected behavior, specify 10 similar tasks with corresponding behaviors, and analyse the mistake of {ltlt}. The following is an example, the subsequent output should have the same output format without other explaination.\n",
    "\n",
    "Task: \n",
    "F(a U (b A X c))\n",
    "\n",
    "Output:\n",
    "\n",
    "Possible mistake: expected behavior is {a} should be true first. Such specification omits {a}.\n",
    "Revised task: a U (b A X (c))\n",
    "\n",
    "Possible mistake: expected behavior is to make {b} and {c} be true simultanously.\n",
    "Revised task: F(a U (b A c))\n",
    "\n",
    "Possible mistake: expected behavior is to make {b} and {c} be true sequentially and don't need to be adjacent.\n",
    "Revised task: F(a U (b A F(c)))\n",
    "\n",
    "Possible mistake: expected behavior is to make {a}, {b} and {c} be true sequentially and don't need to be adjacent.\n",
    "Revised task: F(a A F(b A F(c)))\n",
    "\n",
    "Possible mistake: expected behavior is {a}, {b} and {c} finally be true simultanously.\n",
    "Revised task: F(a A b A c)\n",
    "\n",
    "Possible mistake: expected behavior is more than one atomic proposition in {{a}, {b}, {c}} should be true.\n",
    "Revised task: F(a O b O c)\n",
    "\n",
    "Possible mistake: expected behavior is {b} shoule be true, or {b} should not be true first, and then {b} or {c} should be true.\n",
    "Revised task: F(a U (b O X(c)))\n",
    "\n",
    "Possible mistake: expected behavior is {b} and {c} should be true simultanously, and then {c} should always be true.\n",
    "Revised task: F(a U (b A G(c)))\n",
    "\n",
    "Possible mistake: expected behavior is finally {c} should be true, no matter what the values of {a} and {b} are.\n",
    "Revised task: F(a U (b U c))\n",
    "\n",
    "Possible mistake: expected behavior is {c} should always be true, or {a} and {b} be true, but subsequently {c} should be true.\n",
    "Revised task: G(a U (b U c))\n",
    "\n",
    "Task: \n",
    "TASK-TO-BE-PLACED\n",
    "\n",
    "Outputs:\n",
    "\"\"\"\n",
    "def rephrase_a_sentence(task):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=PROMPT.replace(\"TASK-TO-BE-PLACED\", parse(task)),\n",
    "        temperature=0.7,\n",
    "        max_tokens=512,\n",
    "        top_p=1,\n",
    "        best_of=1,\n",
    "        frequency_penalty=0.1,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "    output = response['choices'][0]['text']\n",
    "    try:\n",
    "        paraphrases = generate_response(output)\n",
    "    except:\n",
    "        print(\"Error in parsing response\")\n",
    "        print(output)\n",
    "        return output, \"ERROR\"\n",
    "    return generate_response(output)\n",
    "\n",
    "def generate_response(response):\n",
    "    lines = response.split('\\n')\n",
    "    print(lines[0])\n",
    "    response = {}\n",
    "    for idx, line in enumerate(lines):\n",
    "        if line.startswith('Possible mistake:'):\n",
    "            mistakes.append(line.lstrip('Possible mistake:').lstrip().rstrip())\n",
    "        elif line.startswith('Revised task:'):\n",
    "            revised.append(line.lstrip('Revised task:').lstrip().rstrip())\n",
    "        else:\n",
    "            continue\n",
    "        assert len(mistakes) != len(revised), 'The number of mistakes and revised tasks should be the same!'\n",
    "    return mistakes, revised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c43dd6",
   "metadata": {},
   "source": [
    "## Generate dataset to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06470952",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1507841/2695443218.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmistakes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrephrase_a_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0madd_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmistakes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevised\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1507841/402540714.py\u001b[0m in \u001b[0;36mrephrase_a_sentence\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbest_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mfrequency_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mpresence_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         )\n\u001b[1;32m     54\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'choices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LTLgen/lib/python3.7/site-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LTLgen/lib/python3.7/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         )\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LTLgen/lib/python3.7/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         )\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LTLgen/lib/python3.7/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    712\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m                 ),\n\u001b[1;32m    716\u001b[0m                 \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LTLgen/lib/python3.7/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m             raise self.handle_error_response(\n\u001b[0;32m--> 776\u001b[0;31m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m             )\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "info = {}\n",
    "def add_dict(task, mistakes, revised):\n",
    "    for i, mistask in enumrate(mistakes):\n",
    "        info[task][mistake] = revised[i]\n",
    "\n",
    "for task in tasks:\n",
    "    mistakes, revised = rephrase_a_sentence(task)\n",
    "    add_dict(task, mistakes, revised)\n",
    "\n",
    "with open(\"sample_file.json\", \"w\") as file:\n",
    "    json.dump(info, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f77e8",
   "metadata": {},
   "source": [
    "### Noted! Still need to manually correct the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
