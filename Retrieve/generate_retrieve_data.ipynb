{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d16ba97",
   "metadata": {},
   "source": [
    "# Generate error message retrieve data\n",
    "## Load LTL tasks from txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8974754",
   "metadata": {},
   "outputs": [],
   "source": [
    "## These tasks are used to train the embedding model and should be stored in '../GA/tasks.txt'.\n",
    "##TODO: load from config\n",
    "LTL_OPS = ['A', 'O', 'N', 'G', 'U', 'X', 'E']\n",
    "APs = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "\n",
    "file_path = \"../GA/normal_task.txt\"\n",
    "with open(file_path) as f:\n",
    "    tasks = f.read().splitlines()\n",
    "print(tasks[0])\n",
    "print(len(tasks))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b5b1e",
   "metadata": {},
   "source": [
    "## Remove the tasks with the same temporal structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bbc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess the tasks.\n",
    "## Remove the AP-repeated tasks.\n",
    "import difflib\n",
    "def compare_tasks(task_a, task_b):\n",
    "    # Return true if two tasks are only different in atomic propositions\n",
    "    d = difflib.Differ()\n",
    "    diffs = list(d.compare(task_a, task_b))\n",
    "    for diff in diffs:\n",
    "        if diff.startswith('+') or diff.startswith('-'):\n",
    "            if diff[-1] in LTL_OPS:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def onlyAP(task, record_task): \n",
    "    # Return true if some task only AP different has been added in list\n",
    "    for record in record_task:\n",
    "        if compare_tasks(task, record):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "from tqdm import tqdm\n",
    "print('Preprocessing tasks...')\n",
    "record_task = [tasks[0]]\n",
    "for i in tqdm(range(len(tasks))):\n",
    "    if onlyAP(tasks[i], record_task):\n",
    "        continue\n",
    "    else:\n",
    "        record_task.append(tasks[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa9194",
   "metadata": {},
   "source": [
    "## Import OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fa84548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, openai\n",
    "# You need to set your OPENAI API key here\n",
    "# https://beta.openai.com/account/api-keys\n",
    "openai.api_key = \"TO_BE_SET\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6edac9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"Given a linear temporal logic task {ltlt}, assume this task doesn't satisfy the expected behavior, specify 5 similar tasks with corresponding behaviors, and analyse the mistake of {ltlt}. The following is an example, the subsequent output should have the same output format without other explaination.\n",
    "\n",
    "Task: \n",
    "F(a U (b A X c))\n",
    "\n",
    "Output:\n",
    "\n",
    "Possible mistake: expected behavior is {a} should be true first. Such specification omits {a}.\n",
    "Revised task: a U (b A X (c))\n",
    "\n",
    "Possible mistake: expected behavior is to make {b} and {c} be true simultanously.\n",
    "Revised task: F(a U (b A c))\n",
    "\n",
    "Possible mistake: expected behavior is to make {b} and {c} be true sequentially and don't need to be adjacent.\n",
    "Revised task: F(a U (b A F(c)))\n",
    "\n",
    "Possible mistake: expected behavior is to make {a}, {b} and {c} be true sequentially and don't need to be adjacent.\n",
    "Revised task: F(a A F(b A F(c)))\n",
    "\n",
    "Possible mistake: expected behavior is {a}, {b} and {c} finally be true simultanously.\n",
    "Revised task: F(a A b A c)\n",
    "\n",
    "Possible mistake: expected behavior is more than one atomic proposition in {{a}, {b}, {c}} should be true.\n",
    "Revised task: F(a O b O c)\n",
    "\n",
    "Possible mistake: expected behavior is {b} shoule be true, or {b} should not be true first, and then {b} or {c} should be true.\n",
    "Revised task: F(a U (b O X(c)))\n",
    "\n",
    "Possible mistake: expected behavior is {b} and {c} should be true simultanously, and then {c} should always be true.\n",
    "Revised task: F(a U (b A G(c)))\n",
    "\n",
    "Possible mistake: expected behavior is finally {c} should be true, no matter what the values of {a} and {b} are.\n",
    "Revised task: F(a U (b U c))\n",
    "\n",
    "Possible mistake: expected behavior is {c} should always be true, or {a} and {b} be true, but subsequently {c} should be true.\n",
    "Revised task: G(a U (b U c))\n",
    "\n",
    "Task: \n",
    "TASK-TO-BE-PLACED\n",
    "\n",
    "Outputs:\n",
    "\"\"\"\n",
    "def rephrase_a_sentence(task):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=PROMPT.replace(\"TASK-TO-BE-PLACED\", task),\n",
    "        temperature=0.7,\n",
    "        max_tokens=512,\n",
    "        top_p=1,\n",
    "        best_of=1,\n",
    "        frequency_penalty=0.1,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "    output = response['choices'][0]['text']\n",
    "    try:\n",
    "        mistakes, revised = generate_response(output)\n",
    "    except:\n",
    "        print(\"Error in parsing response\")\n",
    "        print(output)\n",
    "        return output, \"ERROR\"\n",
    "    #print(mistakes, revised)\n",
    "    return generate_response(output)\n",
    "\n",
    "def generate_response(response):\n",
    "    lines = response.split('\\n')\n",
    "    print(lines[0])\n",
    "    response = {}\n",
    "    mistakes = []\n",
    "    revised = []\n",
    "    for idx, line in enumerate(lines):\n",
    "        if line.startswith('Possible mistake:'):\n",
    "            mistakes.append(line.replace('Possible mistake:', '').lstrip().rstrip())\n",
    "        elif line.startswith('Revised task:'):\n",
    "            revised.append(line.replace('Revised task:', '').lstrip().rstrip())\n",
    "        else:\n",
    "            continue\n",
    "    assert len(mistakes) == len(revised), 'The number of mistakes and revised tasks should be the same!'\n",
    "    return mistakes, revised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c43dd6",
   "metadata": {},
   "source": [
    "## Generate dataset to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06470952",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {}\n",
    "def add_dict(task, mistakes, revised):\n",
    "    info[task] = {}\n",
    "    if len(mistakes) == len(revised):\n",
    "        for i, mistake in enumerate(mistakes):\n",
    "            info[task][mistake] = revised[i]\n",
    "    else:\n",
    "        print('Length of mistakes and revised are not equal!')\n",
    "        r = min(len(mistakes), len(revised))\n",
    "        for i in range(r):\n",
    "            info[task][mistakes[i]] = revised[i]\n",
    "\n",
    "print('Begin to generate responses...')\n",
    "from tqdm import tqdm\n",
    "# for i in tqdm(range(59, int(len(record_task)/10))):\n",
    "for i in tqdm(range(60, int(len(record_task))), leave=None):\n",
    "    task = record_task[i].strip()\n",
    "    mistakes, revised = rephrase_a_sentence(task)\n",
    "    add_dict(task, mistakes, revised)\n",
    "\n",
    "with open(\"retrieve_msg.json\", \"w\") as file:\n",
    "    json.dump(info, file, indent=2)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f77e8",
   "metadata": {},
   "source": [
    "### Note: still need to manually correct the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
